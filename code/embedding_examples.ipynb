{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from correlation import *\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textutils import importer\n",
    "import json\n",
    "\n",
    "annual_report = importer.TextImporter(\"../texts/AnnualReport2017-2018.txt\")\n",
    "with open(\"../ndc_keywords/ndc_south_africa.json\") as f:\n",
    "    ndc_keywords = json.load(f)\n",
    "\n",
    "climate_keywords = ndc_keywords['climate change']\n",
    "policy = [\"policy\", \"integrate\", \"implement\", \"committee\", \"consultation\"]\n",
    "food = [\"nutritions\", \"diets\", \"farm\", \"agriculture\", \"ecology\"]\n",
    "ndc_national_adaption_plan = [\"nap\", \"sector plan\", \"nccrp\", \"vulnerable sector\", \n",
    "                              \"geographic vulnerability\"]\n",
    "ndc_early_warning = [\"system\", \"vulnerability\", \"needs\", \"assessment\", \"network\", \"weather\",\n",
    "   \"earth\", \"observation\", \"academic\", \"community\"]\n",
    "doc = nlp(annual_report.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running NGram correlation on a document\n",
    "\n",
    "NGrams are all possible subsections of a document of length N. NGramCorrelateSpacy is a class that has the\n",
    "ability to break a document up into all possible defined NGrams, then correlate them against a \n",
    "group of keywords to flag for review.\n",
    "\n",
    "Before running any entity tagging operation, the current document's entity list should be cleared, as Spacy \n",
    "prohibits overlapping entities.\n",
    "\n",
    "In this example, we will initialize an NGramCorrelateSpacy object with a list of climate change keywords\n",
    "and set it to tag entities if their correlation surpasses a given value. If the correlation for an NGram \n",
    "surpasses 0.7, as seen in this example, it will be tagged with the flag CLIMATE_N. \n",
    "\n",
    "We start the correlation process by passing the correlator the document, and the size of NGrams we want to analyze.\n",
    "Using N=4 will correlate all possible spans of length 4.\n",
    "\n",
    "After correlation of the possible 4-Grams, we display passeges surrounding five of the flagged entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from n_gram_correlation import NGramCorrelateSpacy\n",
    "ngram_climate_corr = NGramCorrelateSpacy(climate_keywords, 0.7, \"CLIMATE\")\n",
    "ngram_policy_corr = NGramCorrelateSpacy(policy, 0.7, \"POLICY\")\n",
    "ngram_food_corr = NGramCorrelateSpacy(food, 0.7, \"FOOD\")\n",
    "ngram_adaption_corr = NGramCorrelateSpacy(ndc_national_adaption_plan, 0.7, \"ADAPTION\")\n",
    "ngram_warning_corr = NGramCorrelateSpacy(ndc_early_warning, 0.7, \"WARNING\")\n",
    "doc.ents = []\n",
    "ngram_climate_corr.correlate_spans(doc, 4)\n",
    "ngram_policy_corr.correlate_spans(doc, 4)\n",
    "ngram_food_corr.correlate_spans(doc, 4)\n",
    "ngram_adaption_corr.correlate_spans(doc, 4)\n",
    "ngram_warning_corr.correlate_spans(doc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = {\n",
    "    'CLIMATE': \"green\",\n",
    "    'WARNING': \"red\",\n",
    "    \"POLICY\": \"yellow\",\n",
    "    \"FOOD\": \"orange\",\n",
    "    \"ADAPTION\": \"pink\"\n",
    "}\n",
    "for e in doc.ents:\n",
    "    displacy.render(doc[e.start-10:e.end+10], style='ent', options={'colors': colors})\n",
    "# displacy.render(doc, style='ent', options={\"colors\": colors})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other correlation tools\n",
    "\n",
    "## KeywordCorrelator\n",
    "The KeywordCorrelator class is a simple tool to analyze the correlation of any set of strings\n",
    "to a static list of keywords. This class is initialized with a list of keywords that we are\n",
    "interested in. We can then make calls on an instance of this class with a list of strings, \n",
    "and it will return a list of coefficients (cosine similarities) between the embeddings \n",
    "of each sentence and the embeddings of the keywords. The returned similarities\n",
    "are the maximum cosine similarity found amongst a given sentence and all the keyword embeddings.\n",
    "\n",
    "This clase is used as the basis for all other correlators.\n",
    "\n",
    "## SpanCorrelator\n",
    "The SpanCorrelator is a slightly more intelligent version of the generic correlator. It features\n",
    "Spacy integration, allowing it to mark provided sections of a document with tags if the sections\n",
    "score high enough against the embeddings of the initialized keywords. \n",
    "\n",
    "## TokenArrayCorrelator\n",
    "The TokenArrayCorrelator is a specialized version of the SpanCorrelator. It can be passed an array of token arrays\n",
    "which do not have to be consecutive, although the position of tokens in a given array must be in\n",
    "an ascending order by location in the document. It operates similarly to SpanCorrelator, embedding\n",
    "the strings created by the selections of tokens against initialized keywords, then tagging \n",
    "entities in the document which include the token subsets if their cosine similarities \n",
    "pass a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_correlator = TokenArrayCorrelator(climate_keywords, 0.4, \"CLIMATE_TOKEN\")\n",
    "span_correlator = SpanCorrelator(climate_keywords, 0.4, \"CLIMATE_SPAN\")\n",
    "generic_correlator = KeywordCorrelator(climate_keywords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First, explore the generic correlator functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_to_correlate = \"We need to adapt our project to be more resillient to geographical circumstances.\"\n",
    "unrelated_sentence = \"The next time the leaders will meet in paris\"\n",
    "\n",
    "print(generic_correlator([sentence_to_correlate, unrelated_sentence]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the sentence which uses some of the NDC keywords has a much higher embedding score than the unrelated sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, lets see how we can integrate the output of our embedder into Spacy, an NLP library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence_to_correlate+ \" \" +unrelated_sentence)\n",
    "doc.ents = []\n",
    "span_correlator(doc, [s for s in doc.sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_omit = {'to', 'the', 'our', 'we'}\n",
    "tokens_filtered = [[t for t in sent if t.text.lower() not in words_to_omit] for sent in doc.sents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_to_strings = [\" \".join([str(t) for t in passage]) for passage in tokens_filtered]\n",
    "print(filtered_to_strings) # See that stopwords have been removed\n",
    "print(generic_correlator(filtered_to_strings)) # Notice that by removing some stop words, we have boosted the score in the first sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents = []\n",
    "\n",
    "token_correlator(doc, tokens_filtered)\n",
    "displacy.render(doc, style='ent', options={\"colors\": {\"CLIMATE_TOKEN\": \"blue\"}})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75547552c603f22400c6f6e0e4ad2ade15359435e000e6746c53241e37331409"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
